Provider: OpenRouter
Using 500 provided questions

Starting Capabilities Measurement for Subject: llama-3.1-8b-instruct_PopMC_0_difficulty_filtered_500
Configuration: Questions=500, is_human_player=False, temperature=0.0, resample_for_probs=False, nested=None

========== Starting Capability Measuring ==========
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
Data saved to: ./capabilities_test_logs/llama-3.1-8b-instruct_PopMC_0_difficulty_filtered_500_2025-11-29-14-07-12_test_data.json
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
Data saved to: ./capabilities_test_logs/llama-3.1-8b-instruct_PopMC_0_difficulty_filtered_500_2025-11-29-14-07-12_test_data.json
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
Data saved to: ./capabilities_test_logs/llama-3.1-8b-instruct_PopMC_0_difficulty_filtered_500_2025-11-29-14-07-12_test_data.json
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
Data saved to: ./capabilities_test_logs/llama-3.1-8b-instruct_PopMC_0_difficulty_filtered_500_2025-11-29-14-07-12_test_data.json
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
Data saved to: ./capabilities_test_logs/llama-3.1-8b-instruct_PopMC_0_difficulty_filtered_500_2025-11-29-14-07-12_test_data.json
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
Data saved to: ./capabilities_test_logs/llama-3.1-8b-instruct_PopMC_0_difficulty_filtered_500_2025-11-29-14-07-12_test_data.json
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
Data saved to: ./capabilities_test_logs/llama-3.1-8b-instruct_PopMC_0_difficulty_filtered_500_2025-11-29-14-07-12_test_data.json
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
Data saved to: ./capabilities_test_logs/llama-3.1-8b-instruct_PopMC_0_difficulty_filtered_500_2025-11-29-14-07-12_test_data.json
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
Data saved to: ./capabilities_test_logs/llama-3.1-8b-instruct_PopMC_0_difficulty_filtered_500_2025-11-29-14-07-12_test_data.json
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
Data saved to: ./capabilities_test_logs/llama-3.1-8b-instruct_PopMC_0_difficulty_filtered_500_2025-11-29-14-07-12_test_data.json
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
Data saved to: ./capabilities_test_logs/llama-3.1-8b-instruct_PopMC_0_difficulty_filtered_500_2025-11-29-14-07-12_test_data.json
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
Data saved to: ./capabilities_test_logs/llama-3.1-8b-instruct_PopMC_0_difficulty_filtered_500_2025-11-29-14-07-12_test_data.json
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
Data saved to: ./capabilities_test_logs/llama-3.1-8b-instruct_PopMC_0_difficulty_filtered_500_2025-11-29-14-07-12_test_data.json
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
Data saved to: ./capabilities_test_logs/llama-3.1-8b-instruct_PopMC_0_difficulty_filtered_500_2025-11-29-14-07-12_test_data.json
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
Data saved to: ./capabilities_test_logs/llama-3.1-8b-instruct_PopMC_0_difficulty_filtered_500_2025-11-29-14-07-12_test_data.json
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
Data saved to: ./capabilities_test_logs/llama-3.1-8b-instruct_PopMC_0_difficulty_filtered_500_2025-11-29-14-07-12_test_data.json
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
Data saved to: ./capabilities_test_logs/llama-3.1-8b-instruct_PopMC_0_difficulty_filtered_500_2025-11-29-14-07-12_test_data.json
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
Data saved to: ./capabilities_test_logs/llama-3.1-8b-instruct_PopMC_0_difficulty_filtered_500_2025-11-29-14-07-12_test_data.json
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
Data saved to: ./capabilities_test_logs/llama-3.1-8b-instruct_PopMC_0_difficulty_filtered_500_2025-11-29-14-07-12_test_data.json
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
Data saved to: ./capabilities_test_logs/llama-3.1-8b-instruct_PopMC_0_difficulty_filtered_500_2025-11-29-14-07-12_test_data.json
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
Data saved to: ./capabilities_test_logs/llama-3.1-8b-instruct_PopMC_0_difficulty_filtered_500_2025-11-29-14-07-12_test_data.json
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
Data saved to: ./capabilities_test_logs/llama-3.1-8b-instruct_PopMC_0_difficulty_filtered_500_2025-11-29-14-07-12_test_data.json
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
Data saved to: ./capabilities_test_logs/llama-3.1-8b-instruct_PopMC_0_difficulty_filtered_500_2025-11-29-14-07-12_test_data.json
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
Data saved to: ./capabilities_test_logs/llama-3.1-8b-instruct_PopMC_0_difficulty_filtered_500_2025-11-29-14-07-12_test_data.json
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
Data saved to: ./capabilities_test_logs/llama-3.1-8b-instruct_PopMC_0_difficulty_filtered_500_2025-11-29-14-07-12_test_data.json
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
Data saved to: ./capabilities_test_logs/llama-3.1-8b-instruct_PopMC_0_difficulty_filtered_500_2025-11-29-14-07-12_test_data.json
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
Data saved to: ./capabilities_test_logs/llama-3.1-8b-instruct_PopMC_0_difficulty_filtered_500_2025-11-29-14-07-12_test_data.json
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
Data saved to: ./capabilities_test_logs/llama-3.1-8b-instruct_PopMC_0_difficulty_filtered_500_2025-11-29-14-07-12_test_data.json
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
Data saved to: ./capabilities_test_logs/llama-3.1-8b-instruct_PopMC_0_difficulty_filtered_500_2025-11-29-14-07-12_test_data.json
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
Data saved to: ./capabilities_test_logs/llama-3.1-8b-instruct_PopMC_0_difficulty_filtered_500_2025-11-29-14-07-12_test_data.json
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
Data saved to: ./capabilities_test_logs/llama-3.1-8b-instruct_PopMC_0_difficulty_filtered_500_2025-11-29-14-07-12_test_data.json
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
Data saved to: ./capabilities_test_logs/llama-3.1-8b-instruct_PopMC_0_difficulty_filtered_500_2025-11-29-14-07-12_test_data.json
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
Data saved to: ./capabilities_test_logs/llama-3.1-8b-instruct_PopMC_0_difficulty_filtered_500_2025-11-29-14-07-12_test_data.json
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
Data saved to: ./capabilities_test_logs/llama-3.1-8b-instruct_PopMC_0_difficulty_filtered_500_2025-11-29-14-07-12_test_data.json
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
Data saved to: ./capabilities_test_logs/llama-3.1-8b-instruct_PopMC_0_difficulty_filtered_500_2025-11-29-14-07-12_test_data.json
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
Data saved to: ./capabilities_test_logs/llama-3.1-8b-instruct_PopMC_0_difficulty_filtered_500_2025-11-29-14-07-12_test_data.json
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
Data saved to: ./capabilities_test_logs/llama-3.1-8b-instruct_PopMC_0_difficulty_filtered_500_2025-11-29-14-07-12_test_data.json
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
Data saved to: ./capabilities_test_logs/llama-3.1-8b-instruct_PopMC_0_difficulty_filtered_500_2025-11-29-14-07-12_test_data.json
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
Data saved to: ./capabilities_test_logs/llama-3.1-8b-instruct_PopMC_0_difficulty_filtered_500_2025-11-29-14-07-12_test_data.json
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
Data saved to: ./capabilities_test_logs/llama-3.1-8b-instruct_PopMC_0_difficulty_filtered_500_2025-11-29-14-07-12_test_data.json
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
Data saved to: ./capabilities_test_logs/llama-3.1-8b-instruct_PopMC_0_difficulty_filtered_500_2025-11-29-14-07-12_test_data.json
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
Data saved to: ./capabilities_test_logs/llama-3.1-8b-instruct_PopMC_0_difficulty_filtered_500_2025-11-29-14-07-12_test_data.json
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
Data saved to: ./capabilities_test_logs/llama-3.1-8b-instruct_PopMC_0_difficulty_filtered_500_2025-11-29-14-07-12_test_data.json
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
Data saved to: ./capabilities_test_logs/llama-3.1-8b-instruct_PopMC_0_difficulty_filtered_500_2025-11-29-14-07-12_test_data.json
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
Data saved to: ./capabilities_test_logs/llama-3.1-8b-instruct_PopMC_0_difficulty_filtered_500_2025-11-29-14-07-12_test_data.json
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
Data saved to: ./capabilities_test_logs/llama-3.1-8b-instruct_PopMC_0_difficulty_filtered_500_2025-11-29-14-07-12_test_data.json
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
Data saved to: ./capabilities_test_logs/llama-3.1-8b-instruct_PopMC_0_difficulty_filtered_500_2025-11-29-14-07-12_test_data.json
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
Data saved to: ./capabilities_test_logs/llama-3.1-8b-instruct_PopMC_0_difficulty_filtered_500_2025-11-29-14-07-12_test_data.json
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
Data saved to: ./capabilities_test_logs/llama-3.1-8b-instruct_PopMC_0_difficulty_filtered_500_2025-11-29-14-07-12_test_data.json
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
In model_call, provider=OpenRouter, attempt=1
Thread execution error: UnprocessableEntityError: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
Error in llm processing: Error code: 422 - {'error': {'message': 'Provider returned error', 'code': 422, 'metadata': {'raw': '{"message":"top_logprobs is not supported for temperature 0.0","type":"invalid_request_error","param":"top_logprobs","code":"wrong_api_format"}', 'provider_name': 'Cerebras'}}, 'user_id': 'user_2olc3UxrHvMROEYTU2RrqXohqvn'}
In model_call, provider=OpenRouter, attempt=2
Data saved to: ./capabilities_test_logs/llama-3.1-8b-instruct_PopMC_0_difficulty_filtered_500_2025-11-29-14-07-12_test_data.json

Capabilities Test Complete. Accuracy: 53.20% (266/500)
Data saved to: ./capabilities_test_logs/llama-3.1-8b-instruct_PopMC_0_difficulty_filtered_500_2025-11-29-14-07-12_test_data.json
Capabilities measurement completed. Results saved to: ./capabilities_test_logs/llama-3.1-8b-instruct_PopMC_0_difficulty_filtered_500_2025-11-29-14-07-12_test_data.json
