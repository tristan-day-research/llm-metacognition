{"type": "instruct_eval_sample", "qid": "self_easy_other_hard_69", "question": "In TensorFlow, which method is used to create a model from layers: tf.Model(), tf.Sequential(), or tf.create_model()?", "model_answer": "D", "correct_answer": "D", "predicted_confidence_letter": "F", "entropy": 0.51171875, "expected_confidence": 65.12969970703125, "expected_other_confidence": 59.95697021484375, "loss": 1.28125}
{"type": "instruct_eval_sample", "qid": "self_easy_other_hard_96", "question": "What method is used to shuffle data in a PyTorch DataLoader: shuffle_data(), shuffle(), or randomize()?", "model_answer": "C", "correct_answer": "C", "predicted_confidence_letter": "C", "entropy": 0.1171875, "expected_confidence": 52.609710693359375, "expected_other_confidence": 47.3626708984375, "loss": 2.2526543140411377}
{"type": "instruct_eval_sample", "qid": "self_easy_other_hard_88", "question": "What method in TensorFlow applies a gradient descent update: optimizer.apply_gradients(), optimizer.update(), or optimizer.step()?", "model_answer": "C", "correct_answer": "A", "predicted_confidence_letter": "G", "entropy": 0.06689453125, "expected_confidence": 71.32354736328125, "expected_other_confidence": 61.246185302734375, "loss": 1.6484360694885254}
{"type": "instruct_eval_sample", "qid": "self_easy_other_hard_11", "question": "In TensorFlow, which function is used to create a placeholder: tf.placeholder(), tf.variable(), or tf.tensor()?", "model_answer": "A", "correct_answer": "A", "predicted_confidence_letter": "G", "entropy": 0.0003719329833984375, "expected_confidence": 85.62550354003906, "expected_other_confidence": 77.15362548828125, "loss": 0.828125}
{"type": "instruct_eval_sample", "qid": "self_easy_other_hard_70", "question": "What is the method to create a linear layer in PyTorch: nn.Linear(), nn.Dense(), or nn.FullyConnected()?", "model_answer": "A", "correct_answer": "A", "predicted_confidence_letter": "G", "entropy": 0.17578125, "expected_confidence": 77.71614074707031, "expected_other_confidence": 67.0721435546875, "loss": 0.9303023219108582}
{"type": "instruct_eval_sample", "qid": "self_easy_other_hard_62", "question": "What function is used to generate random numbers in PyTorch: torch.random(), torch.rand(), or torch.randn()?", "model_answer": "C", "correct_answer": "B", "predicted_confidence_letter": "G", "entropy": 0.1708984375, "expected_confidence": 72.87635803222656, "expected_other_confidence": 65.63766479492188, "loss": 1.0952303409576416}
{"type": "instruct_eval_sample", "qid": "self_easy_other_hard_39", "question": "What method is used to detach a tensor from the computation graph in PyTorch: detach(), stop_grad(), or freeze()?", "model_answer": "D", "correct_answer": "D", "predicted_confidence_letter": "D", "entropy": 0.0517578125, "expected_confidence": 60.5352783203125, "expected_other_confidence": 59.2840576171875, "loss": 1.8671875}
{"type": "instruct_eval_sample", "qid": "self_easy_other_hard_75", "question": "What method is used to flatten a tensor in PyTorch: tensor.flatten(), tensor.reshape(), or tensor.view()?", "model_answer": "D", "correct_answer": "C", "predicted_confidence_letter": "F", "entropy": 0.02685546875, "expected_confidence": 68.23333740234375, "expected_other_confidence": 60.95542907714844, "loss": 1.8359375}
{"type": "instruct_eval_sample", "qid": "self_easy_other_hard_1", "question": "What method moves a PyTorch model to GPU: model.cuda(), model.to('cuda'), or model.gpu()?", "model_answer": "D", "correct_answer": "D", "predicted_confidence_letter": "G", "entropy": 0.6640625, "expected_confidence": 59.06425476074219, "expected_other_confidence": 55.480499267578125, "loss": 2.46875}
{"type": "instruct_eval_sample", "qid": "self_easy_other_hard_44", "question": "What's the parameter name for vocabulary size in GPT2Config: vocab_size, n_vocab, or vocabulary_size?", "model_answer": "A", "correct_answer": "A", "predicted_confidence_letter": "G", "entropy": 0.09814453125, "expected_confidence": 61.46942138671875, "expected_other_confidence": 46.0284423828125, "loss": 1.8512253761291504}
{"type": "instruct_eval_sample", "qid": "self_easy_other_hard_64", "question": "In TensorFlow, what is the correct way to create a dataset from a numpy array: tf.data.Dataset.from_tensor_slices(), tf.data.Dataset.from_array(), or tf.data.Dataset.from_numpy()?", "model_answer": "A", "correct_answer": "A", "predicted_confidence_letter": "G", "entropy": 0.11962890625, "expected_confidence": 68.97979736328125, "expected_other_confidence": 63.20556640625, "loss": 1.8904542922973633}
{"type": "instruct_eval_sample", "qid": "self_easy_other_hard_81", "question": "What method is used to load a pre-trained model in Hugging Face Transformers: from_pretrained(), load_model(), or import_model()?", "model_answer": "D", "correct_answer": "D", "predicted_confidence_letter": "D", "entropy": 0.0027923583984375, "expected_confidence": 64.75616455078125, "expected_other_confidence": 65.77880859375, "loss": 1.4921875}
{"type": "instruct_eval_sample", "qid": "self_easy_other_hard_78", "question": "What parameter specifies the batch size in Keras fit method: batch_size, size, or batch?", "model_answer": "C", "correct_answer": "C", "predicted_confidence_letter": "G", "entropy": 0.02490234375, "expected_confidence": 63.840179443359375, "expected_other_confidence": 62.866973876953125, "loss": 1.671875}
{"type": "instruct_eval_sample", "qid": "self_easy_other_hard_17", "question": "What is the return type of torch.split() in PyTorch: tuple, list, or tensor?", "model_answer": "D", "correct_answer": "D", "predicted_confidence_letter": "G", "entropy": 0.1904296875, "expected_confidence": 63.2666015625, "expected_other_confidence": 59.11224365234375, "loss": 1.3984813690185547}
{"type": "instruct_eval_sample", "qid": "self_easy_other_hard_56", "question": "What is the parameter name for the number of attention heads in BertConfig: num_attention_heads, attention_heads, or n_heads?", "model_answer": "C", "correct_answer": "C", "predicted_confidence_letter": "G", "entropy": 0.2890625, "expected_confidence": 64.813232421875, "expected_other_confidence": 54.17022705078125, "loss": 1.244245171546936}
{"type": "instruct_eval_sample", "qid": "self_easy_other_hard_66", "question": "What is the return type of model.forward() in PyTorch: Tensor, List, or Dict?", "model_answer": "A", "correct_answer": "A", "predicted_confidence_letter": "G", "entropy": 0.00921630859375, "expected_confidence": 67.750244140625, "expected_other_confidence": 63.68194580078125, "loss": 1.65625}
{"type": "instruct_eval_sample", "qid": "self_easy_other_hard_28", "question": "What class is used for linear layers in PyTorch: nn.Linear, nn.Dense, or nn.FullyConnected?", "model_answer": "B", "correct_answer": "B", "predicted_confidence_letter": "G", "entropy": 0.10791015625, "expected_confidence": 75.85235595703125, "expected_other_confidence": 59.4110107421875, "loss": 1.4511842727661133}
{"type": "instruct_eval_sample", "qid": "self_easy_other_hard_55", "question": "What function in PyTorch is used for dropout: torch.dropout(), torch.nn.Dropout(), or torch.dropout_layer()?", "model_answer": "B", "correct_answer": "B", "predicted_confidence_letter": "G", "entropy": 0.287109375, "expected_confidence": 70.8148193359375, "expected_other_confidence": 61.5673828125, "loss": 1.1262153387069702}
{"type": "instruct_eval_sample", "qid": "self_easy_other_hard_30", "question": "What method in sklearn is used to fit a model: fit_model(), train(), or fit()?", "model_answer": "C", "correct_answer": "C", "predicted_confidence_letter": "G", "entropy": 0.00103759765625, "expected_confidence": 68.00735473632812, "expected_other_confidence": 59.80377197265625, "loss": 1.609375}
{"type": "instruct_eval_sample", "qid": "self_easy_other_hard_60", "question": "What is the parameter name for the dropout probability in nn.Dropout: p, dropout_prob, or drop_prob?", "model_answer": "A", "correct_answer": "A", "predicted_confidence_letter": "G", "entropy": 0.69140625, "expected_confidence": 64.342041015625, "expected_other_confidence": 51.839599609375, "loss": 2.1875}
{"type": "instruct_eval_sample", "qid": "self_easy_other_hard_87", "question": "What argument is used to specify the batch size in PyTorch's DataLoader: batch_size, size, or batch_sz?", "model_answer": "B", "correct_answer": "B", "predicted_confidence_letter": "G", "entropy": 0.0400390625, "expected_confidence": 74.18228149414062, "expected_other_confidence": 59.3511962890625, "loss": 1.296875}
{"type": "instruct_eval_sample", "qid": "self_easy_other_hard_12", "question": "What method is used to load a model in PyTorch: model.load(), torch.load_model(), or torch.load()?", "model_answer": "A", "correct_answer": "C", "predicted_confidence_letter": "G", "entropy": 1.0546875, "expected_confidence": 64.25018310546875, "expected_other_confidence": 53.9825439453125, "loss": 2.515928030014038}
{"type": "instruct_eval_sample", "qid": "self_easy_other_hard_31", "question": "In PyTorch, what method is used to perform a forward pass: model.forward(), model(), or model.predict()?", "model_answer": "A", "correct_answer": "D", "predicted_confidence_letter": "G", "entropy": 0.0927734375, "expected_confidence": 76.11846923828125, "expected_other_confidence": 69.1583251953125, "loss": 1.2655609846115112}
{"type": "instruct_eval_sample", "qid": "self_easy_other_hard_71", "question": "What method is used to set the seed for random number generation in PyTorch: torch.manual_seed(), torch.set_seed(), or torch.random_seed()?", "model_answer": "C", "correct_answer": "C", "predicted_confidence_letter": "G", "entropy": 0.06787109375, "expected_confidence": 58.45306396484375, "expected_other_confidence": 57.24884033203125, "loss": 1.9687482118606567}
{"type": "instruct_eval_sample", "qid": "self_easy_other_hard_47", "question": "What is the method to load a pretrained model in Hugging Face Transformers: from_pretrained(), load_model(), or load_pretrained()?", "model_answer": "A", "correct_answer": "A", "predicted_confidence_letter": "G", "entropy": 0.000762939453125, "expected_confidence": 77.26356506347656, "expected_other_confidence": 65.97427368164062, "loss": 1.2265625}
{"type": "instruct_eval_sample", "qid": "self_easy_other_hard_6", "question": "Does model.eval() disable dropout: yes, no, or only in training mode?", "model_answer": "C", "correct_answer": "B", "predicted_confidence_letter": "C", "entropy": 0.921875, "expected_confidence": 52.171630859375, "expected_other_confidence": 50.1806640625, "loss": 2.546875}
{"type": "instruct_eval_sample", "qid": "self_easy_other_hard_15", "question": "In Keras, what argument of fit() specifies the number of epochs: epochs, num_epochs, or iterations?", "model_answer": "D", "correct_answer": "D", "predicted_confidence_letter": "D", "entropy": 0.052490234375, "expected_confidence": 56.46697998046875, "expected_other_confidence": 50.6439208984375, "loss": 2.078124761581421}
{"type": "instruct_eval_sample", "qid": "self_easy_other_hard_80", "question": "What method do you call to compute gradients in PyTorch: loss.backward(), loss.grad(), or loss.compute_grad()?", "model_answer": "A", "correct_answer": "A", "predicted_confidence_letter": "G", "entropy": 0.0004119873046875, "expected_confidence": 78.05877685546875, "expected_other_confidence": 70.687255859375, "loss": 1.375}
{"type": "instruct_eval_sample", "qid": "self_easy_other_hard_91", "question": "What method in PyTorch concatenates tensors along a specified dimension: torch.concat(), torch.join(), or torch.cat()?", "model_answer": "D", "correct_answer": "D", "predicted_confidence_letter": "G", "entropy": 0.0264892578125, "expected_confidence": 66.52656555175781, "expected_other_confidence": 59.871978759765625, "loss": 1.828125}
{"type": "instruct_eval_sample", "qid": "self_easy_other_hard_10", "question": "What parameter controls the dropout rate in nn.Dropout: p, rate, or dropout_rate?", "model_answer": "B", "correct_answer": "A", "predicted_confidence_letter": "F", "entropy": 0.625, "expected_confidence": 56.0791015625, "expected_other_confidence": 52.4285888671875, "loss": 1.9296875}
{"type": "instruct_eval_sample", "qid": "self_easy_other_hard_40", "question": "What method moves a PyTorch model to GPU: model.cuda(), model.to('cuda'), or model.gpu()?", "model_answer": "D", "correct_answer": "C", "predicted_confidence_letter": "D", "entropy": 0.1982421875, "expected_confidence": 59.425811767578125, "expected_other_confidence": 58.027801513671875, "loss": 1.5156304836273193}
{"type": "instruct_eval_sample", "qid": "self_easy_other_hard_29", "question": "What function is used to apply a softmax operation in PyTorch: torch.softmax(), torch.nn.softmax(), or nn.softmax()?", "model_answer": "C", "correct_answer": "B", "predicted_confidence_letter": "G", "entropy": 0.1591796875, "expected_confidence": 78.7789535522461, "expected_other_confidence": 66.099853515625, "loss": 0.7932433485984802}
{"type": "instruct_eval_sample", "qid": "self_easy_other_hard_27", "question": "What method is used to compute the loss in PyTorch: loss_fn(), compute_loss(), or loss()?", "model_answer": "C", "correct_answer": "B", "predicted_confidence_letter": "G", "entropy": 0.78515625, "expected_confidence": 72.66525268554688, "expected_other_confidence": 59.53216552734375, "loss": 2.328125}
{"type": "instruct_eval_sample", "qid": "self_easy_other_hard_84", "question": "What function is used to create a tensor from a NumPy array in PyTorch: torch.from_numpy(), torch.tensor(), or torch.as_tensor()?", "model_answer": "C", "correct_answer": "B", "predicted_confidence_letter": "G", "entropy": 0.62890625, "expected_confidence": 75.13130187988281, "expected_other_confidence": 63.9556884765625, "loss": 2.40625}
{"type": "instruct_eval_sample", "qid": "self_easy_other_hard_89", "question": "What is the default activation function in Keras Dense layers: relu, sigmoid, or linear?", "model_answer": "D", "correct_answer": "B", "predicted_confidence_letter": "D", "entropy": 0.04541015625, "expected_confidence": 60.02685546875, "expected_other_confidence": 61.33575439453125, "loss": 1.984375}
{"type": "instruct_eval_sample", "qid": "self_easy_other_hard_48", "question": "What method is used to compute the loss in PyTorch: loss_fn(), compute_loss(), or cross_entropy()?", "model_answer": "A", "correct_answer": "C", "predicted_confidence_letter": "G", "entropy": 0.66015625, "expected_confidence": 70.47500610351562, "expected_other_confidence": 60.3680419921875, "loss": 2.1875}
{"type": "instruct_eval_sample", "qid": "self_easy_other_hard_25", "question": "What method is used to add a layer to a Sequential model in Keras: model.add(), model.insert(), or model.append()?", "model_answer": "B", "correct_answer": "B", "predicted_confidence_letter": "G", "entropy": 0.0028839111328125, "expected_confidence": 75.78239440917969, "expected_other_confidence": 67.86712646484375, "loss": 1.109375}
{"type": "instruct_eval_sample", "qid": "self_easy_other_hard_2", "question": "Does tokenizer.encode() return a list or tensor in Hugging Face Transformers?", "model_answer": "A", "correct_answer": "A", "predicted_confidence_letter": "G", "entropy": 0.26171875, "expected_confidence": 73.86093139648438, "expected_other_confidence": 68.409423828125, "loss": 1.0546882152557373}
{"type": "instruct_eval_sample", "qid": "self_easy_other_hard_46", "question": "To freeze parameters: param.requires_grad = False or param.freeze()?", "model_answer": "D", "correct_answer": "D", "predicted_confidence_letter": "D", "entropy": 0.119140625, "expected_confidence": 53.253936767578125, "expected_other_confidence": 52.7020263671875, "loss": 2.1417994499206543}
{"type": "instruct_eval_sample", "qid": "self_easy_other_hard_97", "question": "What does model.parameters() return in PyTorch: list of parameters, dict of parameters, or a tensor?", "model_answer": "D", "correct_answer": "D", "predicted_confidence_letter": "G", "entropy": 0.1201171875, "expected_confidence": 68.12744140625, "expected_other_confidence": 59.097900390625, "loss": 1.8336679935455322}
{"type": "instruct_eval_sample", "qid": "self_easy_other_hard_45", "question": "Does model.eval() disable dropout: yes, no, or only in training mode?", "model_answer": "C", "correct_answer": "A", "predicted_confidence_letter": "C", "entropy": 0.7734375, "expected_confidence": 52.218017578125, "expected_other_confidence": 50.460205078125, "loss": 2.109375}
{"type": "instruct_eval_sample", "qid": "self_easy_other_hard_95", "question": "Which function is used to convert a PyTorch tensor to a NumPy array: tensor.numpy(), tensor.as_numpy(), or tensor.to_numpy()?", "model_answer": "B", "correct_answer": "B", "predicted_confidence_letter": "G", "entropy": 0.00823974609375, "expected_confidence": 65.23193359375, "expected_other_confidence": 59.96673583984375, "loss": 1.84375}
{"type": "instruct_eval_sample", "qid": "self_easy_other_hard_37", "question": "In TensorFlow, what method is used to evaluate a model: model.evaluate(), model.test(), or model.score()?", "model_answer": "B", "correct_answer": "B", "predicted_confidence_letter": "G", "entropy": 0.008544921875, "expected_confidence": 69.62890625, "expected_other_confidence": 64.07745361328125, "loss": 1.6328125}
{"type": "instruct_eval_sample", "qid": "self_easy_other_hard_23", "question": "What method is used to generate random numbers in NumPy: np.random(), np.rand(), or np.random_numbers()?", "model_answer": "A", "correct_answer": "A", "predicted_confidence_letter": "G", "entropy": 0.00012683868408203125, "expected_confidence": 74.40635681152344, "expected_other_confidence": 65.87890625, "loss": 1.5703125}
{"type": "instruct_eval_sample", "qid": "self_easy_other_hard_85", "question": "What method is used to save a PyTorch model: model.save(), torch.save(), or model.serialize()?", "model_answer": "D", "correct_answer": "D", "predicted_confidence_letter": "G", "entropy": 0.62109375, "expected_confidence": 66.38214111328125, "expected_other_confidence": 61.356201171875, "loss": 2.40625}
{"type": "instruct_eval_sample", "qid": "self_easy_other_hard_82", "question": "What is the return type of model.forward() in PyTorch: tensor, list, or dict?", "model_answer": "D", "correct_answer": "D", "predicted_confidence_letter": "D", "entropy": 0.0189208984375, "expected_confidence": 60.181732177734375, "expected_other_confidence": 62.224578857421875, "loss": 1.9765625}
{"type": "instruct_eval_sample", "qid": "self_easy_other_hard_74", "question": "What is the method to get the shape of a tensor in PyTorch: tensor.shape(), tensor.size(), or tensor.dim()?", "model_answer": "C", "correct_answer": "D", "predicted_confidence_letter": "G", "entropy": 0.033447265625, "expected_confidence": 64.42981719970703, "expected_other_confidence": 58.61907958984375, "loss": 1.953125}
{"type": "instruct_eval_sample", "qid": "self_easy_other_hard_65", "question": "What is the name of the method to apply the ReLU activation function in PyTorch: torch.ReLU(), nn.ReLU(), or torch.activation.ReLU()?", "model_answer": "C", "correct_answer": "D", "predicted_confidence_letter": "G", "entropy": 0.74609375, "expected_confidence": 70.11764526367188, "expected_other_confidence": 57.59307861328125, "loss": 2.328125}
{"type": "instruct_eval_sample", "qid": "self_easy_other_hard_68", "question": "What is the default value of num_return_sequences in Hugging Face Transformers: 1, 0, or None?", "model_answer": "D", "correct_answer": "D", "predicted_confidence_letter": "G", "entropy": 0.94921875, "expected_confidence": 60.09033203125, "expected_other_confidence": 54.43603515625, "loss": 1.9453125}
{"type": "instruct_eval_sample", "qid": "self_easy_other_hard_7", "question": "To freeze parameters: param.requires_grad = False or param.freeze()?", "model_answer": "D", "correct_answer": "D", "predicted_confidence_letter": "D", "entropy": 0.042724609375, "expected_confidence": 56.154937744140625, "expected_other_confidence": 53.966827392578125, "loss": 2.046875}
{"type": "instruct_eval_sample", "qid": "self_easy_other_hard_18", "question": "What function is used to create a tensor in NumPy: np.array(), np.tensor(), or np.create()?", "model_answer": "D", "correct_answer": "D", "predicted_confidence_letter": "G", "entropy": 0.0284423828125, "expected_confidence": 67.17262268066406, "expected_other_confidence": 64.5135498046875, "loss": 1.6328125}
{"type": "instruct_eval_sample", "qid": "self_easy_other_hard_58", "question": "To convert a tensor to a NumPy array in PyTorch, use: tensor.numpy(), tensor.as_numpy(), or tensor.to_numpy()?", "model_answer": "D", "correct_answer": "D", "predicted_confidence_letter": "D", "entropy": 0.0111083984375, "expected_confidence": 54.166908264160156, "expected_other_confidence": 59.6221923828125, "loss": 2.109375}
{"type": "instruct_eval_sample", "qid": "self_easy_other_hard_43", "question": "To concatenate tensors along dim 0, use: torch.cat(), torch.stack(), or torch.concat()?", "model_answer": "A", "correct_answer": "A", "predicted_confidence_letter": "G", "entropy": 0.09814453125, "expected_confidence": 69.45796966552734, "expected_other_confidence": 57.9913330078125, "loss": 1.6793502569198608}
{"type": "instruct_eval_sample", "qid": "self_easy_other_hard_35", "question": "What method is used to clear gradients in PyTorch: optimizer.clear_grad(), optimizer.zero_grad(), or optimizer.reset_grad()?", "model_answer": "A", "correct_answer": "A", "predicted_confidence_letter": "G", "entropy": 0.0125732421875, "expected_confidence": 63.341064453125, "expected_other_confidence": 53.6260986328125, "loss": 1.9375}
{"type": "instruct_eval_sample", "qid": "self_easy_other_hard_32", "question": "What attribute in the optimizer defines learning rates in PyTorch: lr, learning_rate, or rate?", "model_answer": "D", "correct_answer": "D", "predicted_confidence_letter": "D", "entropy": 0.1337890625, "expected_confidence": 57.098388671875, "expected_other_confidence": 53.38134765625, "loss": 1.8816931247711182}
{"type": "instruct_eval_sample", "qid": "self_easy_other_hard_24", "question": "What attribute of nn.Module checks if the model is in evaluation mode: .is_eval(), .eval_mode(), or .training?", "model_answer": "D", "correct_answer": "D", "predicted_confidence_letter": "F", "entropy": 0.1396484375, "expected_confidence": 64.5428466796875, "expected_other_confidence": 55.12664794921875, "loss": 1.5963659286499023}
{"type": "instruct_eval_sample", "qid": "self_easy_other_hard_93", "question": "What method in TensorFlow's Keras API compiles a model: model.compile_model(), model.compile(), or model.build()?", "model_answer": "A", "correct_answer": "A", "predicted_confidence_letter": "G", "entropy": 0.00168609619140625, "expected_confidence": 72.47787475585938, "expected_other_confidence": 63.680419921875, "loss": 1.46875}
{"type": "instruct_eval_sample", "qid": "self_easy_other_hard_22", "question": "To create a dataset in PyTorch, which class is used: Dataset, DataLoader, or DataSet?", "model_answer": "D", "correct_answer": "D", "predicted_confidence_letter": "D", "entropy": 0.0262451171875, "expected_confidence": 62.474517822265625, "expected_other_confidence": 60.15045166015625, "loss": 1.8203125}
{"type": "instruct_eval_sample", "qid": "self_easy_other_hard_34", "question": "What method is used to shuffle data in PyTorch DataLoader: shuffle_data(), randomize(), or shuffle()?", "model_answer": "B", "correct_answer": "B", "predicted_confidence_letter": "G", "entropy": 0.0264892578125, "expected_confidence": 60.9698486328125, "expected_other_confidence": 50.92071533203125, "loss": 1.90625}
{"type": "instruct_eval_sample", "qid": "self_easy_other_hard_90", "question": "What method is used to initialize weights in a Keras layer: layer.initialize_weights(), layer.build(), or layer.kernel_initializer?", "model_answer": "D", "correct_answer": "A", "predicted_confidence_letter": "F", "entropy": 0.68359375, "expected_confidence": 58.361358642578125, "expected_other_confidence": 55.4693603515625, "loss": 1.9375}
{"type": "instruct_eval_sample", "qid": "self_easy_other_hard_21", "question": "What method is used to save a model in PyTorch: model.save(), torch.save(), or model.store()?", "model_answer": "B", "correct_answer": "B", "predicted_confidence_letter": "G", "entropy": 0.30078125, "expected_confidence": 64.52125549316406, "expected_other_confidence": 59.942626953125, "loss": 1.3895797729492188}
{"type": "instruct_eval_sample", "qid": "self_easy_other_hard_26", "question": "What parameter specifies the batch size in DataLoader: batch_size, size, or num_samples?", "model_answer": "D", "correct_answer": "D", "predicted_confidence_letter": "D", "entropy": 0.034912109375, "expected_confidence": 59.927215576171875, "expected_other_confidence": 53.89312744140625, "loss": 1.875}
{"type": "instruct_eval_sample", "qid": "self_easy_other_hard_49", "question": "What is the default value of return_dict in Hugging Face Transformers model forward methods: True, False, or None?", "model_answer": "C", "correct_answer": "D", "predicted_confidence_letter": "G", "entropy": 0.6875, "expected_confidence": 64.37652587890625, "expected_other_confidence": 54.27978515625, "loss": 2.171875}
{"type": "instruct_eval_sample", "qid": "self_easy_other_hard_5", "question": "What's the parameter name for vocabulary size in GPT2Config: vocab_size, n_vocab, or vocabulary_size?", "model_answer": "C", "correct_answer": "C", "predicted_confidence_letter": "G", "entropy": 0.2177734375, "expected_confidence": 55.843658447265625, "expected_other_confidence": 43.8104248046875, "loss": 1.4453130960464478}
{"type": "instruct_eval_sample", "qid": "self_easy_other_hard_98", "question": "What parameter specifies the optimizer's momentum in PyTorch: momentum, beta, or speed?", "model_answer": "B", "correct_answer": "B", "predicted_confidence_letter": "G", "entropy": 0.53515625, "expected_confidence": 54.28924560546875, "expected_other_confidence": 53.7225341796875, "loss": 1.6409724950790405}
{"type": "instruct_eval_sample", "qid": "self_easy_other_hard_3", "question": "What attribute stores hidden size in BertConfig: hidden_size, d_model, or embedding_dim?", "model_answer": "D", "correct_answer": "B", "predicted_confidence_letter": "G", "entropy": 1.109375, "expected_confidence": 56.3507080078125, "expected_other_confidence": 48.7225341796875, "loss": 1.9843943119049072}
{"type": "instruct_eval_sample", "qid": "self_easy_other_hard_41", "question": "Does tokenizer.encode() return a list or tensor in Hugging Face Transformers?", "model_answer": "C", "correct_answer": "A", "predicted_confidence_letter": "G", "entropy": 0.5546875, "expected_confidence": 74.06913757324219, "expected_other_confidence": 70.46478271484375, "loss": 1.7183845043182373}
{"type": "instruct_eval_sample", "qid": "self_easy_other_hard_83", "question": "What attribute in torch.optim.Adam stores the learning rate: lr, learning_rate, or alpha?", "model_answer": "B", "correct_answer": "B", "predicted_confidence_letter": "G", "entropy": 0.2734375, "expected_confidence": 71.12213134765625, "expected_other_confidence": 62.8076171875, "loss": 1.1172175407409668}
{"type": "instruct_eval_sample", "qid": "self_easy_other_hard_79", "question": "What method is used to generate predictions with a model in PyTorch: model.predict(), model.forward(), or model.call()?", "model_answer": "D", "correct_answer": "D", "predicted_confidence_letter": "F", "entropy": 0.1337890625, "expected_confidence": 62.31315612792969, "expected_other_confidence": 58.0133056640625, "loss": 1.790174126625061}
{"type": "instruct_eval_sample", "qid": "self_easy_other_hard_61", "question": "What method is used to initialize weights in PyTorch: torch.init(), torch.weight_init(), or torch.initialize_weights()?", "model_answer": "C", "correct_answer": "C", "predicted_confidence_letter": "C", "entropy": 0.01239013671875, "expected_confidence": 48.37066650390625, "expected_other_confidence": 48.5076904296875, "loss": 2.046875}
{"type": "instruct_eval_sample", "qid": "self_easy_other_hard_33", "question": "What argument in nn.Conv2d specifies the number of output channels: out_channels, num_output, or n_out?", "model_answer": "A", "correct_answer": "A", "predicted_confidence_letter": "G", "entropy": 0.00138092041015625, "expected_confidence": 73.90411376953125, "expected_other_confidence": 56.09832763671875, "loss": 1.2578125}
{"type": "instruct_eval_sample", "qid": "self_easy_other_hard_77", "question": "What method is used to evaluate a model in Keras: model.evaluate(), model.test(), or model.val()?", "model_answer": "A", "correct_answer": "A", "predicted_confidence_letter": "G", "entropy": 0.000827789306640625, "expected_confidence": 76.54838562011719, "expected_other_confidence": 65.521240234375, "loss": 1.453125}
{"type": "instruct_eval_sample", "qid": "self_easy_other_hard_9", "question": "What is the default learning rate for Adam optimizer in PyTorch: 0.001, 0.01, or 0.1?", "model_answer": "C", "correct_answer": "C", "predicted_confidence_letter": "G", "entropy": 0.421875, "expected_confidence": 65.711669921875, "expected_other_confidence": 57.020263671875, "loss": 1.875}
{"type": "instruct_eval_sample", "qid": "self_easy_other_hard_54", "question": "What method in PyTorch is used to set a model to training mode: model.train(), model.set_train(), or model.switch_to_train()?", "model_answer": "D", "correct_answer": "D", "predicted_confidence_letter": "D", "entropy": 0.01312255859375, "expected_confidence": 56.03736877441406, "expected_other_confidence": 56.41693115234375, "loss": 1.8515625}
{"type": "instruct_eval_sample", "qid": "self_easy_other_hard_51", "question": "What is the correct way to initialize a TensorFlow variable: tf.Variable(value), tf.Tensor(value), or tf.create_variable(value)?", "model_answer": "A", "correct_answer": "A", "predicted_confidence_letter": "G", "entropy": 0.01806640625, "expected_confidence": 75.93276977539062, "expected_other_confidence": 65.45013427734375, "loss": 1.6484375}
{"type": "instruct_eval_sample", "qid": "self_easy_other_hard_14", "question": "What method is used for backpropagation in TensorFlow: loss.backprop(), loss.backward(), or loss.grad()?", "model_answer": "D", "correct_answer": "D", "predicted_confidence_letter": "G", "entropy": 0.0308837890625, "expected_confidence": 61.2652587890625, "expected_other_confidence": 59.12506103515625, "loss": 1.9375}
{"type": "instruct_eval_sample", "qid": "self_easy_other_hard_94", "question": "What attribute in TensorFlow's optimizer controls the learning rate decay: learning_rate, lr_schedule, or decay_rate?", "model_answer": "A", "correct_answer": "C", "predicted_confidence_letter": "G", "entropy": 0.064453125, "expected_confidence": 63.348388671875, "expected_other_confidence": 54.3603515625, "loss": 1.9296863079071045}
{"type": "instruct_eval_sample", "qid": "self_easy_other_hard_92", "question": "What parameter in the LSTM class specifies the number of layers: num_layers, layers, or n_layers?", "model_answer": "B", "correct_answer": "B", "predicted_confidence_letter": "C", "entropy": 0.318359375, "expected_confidence": 43.0377197265625, "expected_other_confidence": 42.8857421875, "loss": 2.0524418354034424}
{"type": "instruct_eval_sample", "qid": "self_easy_other_hard_13", "question": "What method is used to set the model to training mode in PyTorch: model.train(), model.training(), or model.set_train()?", "model_answer": "C", "correct_answer": "C", "predicted_confidence_letter": "G", "entropy": 0.049560546875, "expected_confidence": 66.87179565429688, "expected_other_confidence": 58.13507080078125, "loss": 1.7812498807907104}
{"type": "instruct_eval_sample", "qid": "self_easy_other_hard_72", "question": "What is the method to perform backpropagation in TensorFlow: model.backpropagate(), model.backward(), or model.fit()?", "model_answer": "A", "correct_answer": "A", "predicted_confidence_letter": "G", "entropy": 0.1015625, "expected_confidence": 65.0384521484375, "expected_other_confidence": 62.84576416015625, "loss": 1.546562910079956}
{"type": "instruct_eval_sample", "qid": "self_easy_other_hard_38", "question": "What function is used to convert a list to a tensor in PyTorch: torch.tensor(), torch.from_list(), or torch.as_tensor()?", "model_answer": "C", "correct_answer": "C", "predicted_confidence_letter": "G", "entropy": 0.349609375, "expected_confidence": 71.51603698730469, "expected_other_confidence": 64.53262329101562, "loss": 1.2968703508377075}
{"type": "instruct_eval_sample", "qid": "self_easy_other_hard_50", "question": "In TensorFlow, what method is used to compile a model: model.compile(), model.setup(), or model.build()?", "model_answer": "D", "correct_answer": "D", "predicted_confidence_letter": "D", "entropy": 0.0208740234375, "expected_confidence": 63.15196990966797, "expected_other_confidence": 62.70782470703125, "loss": 1.5390625}
{"type": "instruct_eval_sample", "qid": "self_easy_other_hard_63", "question": "What is the method to create a tensor filled with zeros in PyTorch: torch.zeros_like(), torch.zeros(), or torch.empty()?", "model_answer": "D", "correct_answer": "D", "predicted_confidence_letter": "G", "entropy": 0.5859375, "expected_confidence": 76.2548828125, "expected_other_confidence": 64.10614013671875, "loss": 2.5468645095825195}
{"type": "instruct_eval_sample", "qid": "self_easy_other_hard_42", "question": "What attribute stores hidden size in BertConfig: hidden_size, d_model, or embedding_dim?", "model_answer": "A", "correct_answer": "D", "predicted_confidence_letter": "G", "entropy": 0.671875, "expected_confidence": 62.61505126953125, "expected_other_confidence": 53.85986328125, "loss": 2.25}
{"type": "instruct_eval_sample", "qid": "self_easy_other_hard_20", "question": "What attribute of a PyTorch tensor gives the shape: .size(), .shape(), or .dim()?", "model_answer": "B", "correct_answer": "B", "predicted_confidence_letter": "G", "entropy": 0.1630859375, "expected_confidence": 73.17214965820312, "expected_other_confidence": 63.024444580078125, "loss": 1.0090032815933228}
{"type": "instruct_eval_sample", "qid": "self_easy_other_hard_36", "question": "What method is used to flatten a tensor in PyTorch: flatten(), view(), or reshape()?", "model_answer": "C", "correct_answer": "C", "predicted_confidence_letter": "F", "entropy": 0.73046875, "expected_confidence": 60.22224426269531, "expected_other_confidence": 56.854095458984375, "loss": 1.921875}
{"type": "instruct_eval_sample", "qid": "self_easy_other_hard_52", "question": "What method is used to save a model in TensorFlow: model.save(), model.store(), or model.persist()?", "model_answer": "C", "correct_answer": "C", "predicted_confidence_letter": "G", "entropy": 0.0031280517578125, "expected_confidence": 69.57206726074219, "expected_other_confidence": 69.5947265625, "loss": 1.3671875}
{"type": "instruct_eval_sample", "qid": "self_easy_other_hard_76", "question": "What is the return type of model.predict() in Keras: Numpy array, Tensor, or List?", "model_answer": "D", "correct_answer": "D", "predicted_confidence_letter": "D", "entropy": 0.046630859375, "expected_confidence": 63.53157043457031, "expected_other_confidence": 55.567626953125, "loss": 1.7578125}
{"type": "instruct_eval_sample", "qid": "self_easy_other_hard_8", "question": "What method is used to initialize weights in PyTorch: torch.init(), torch.weight_init(), or torch.nn.init()?", "model_answer": "B", "correct_answer": "B", "predicted_confidence_letter": "G", "entropy": 0.0062255859375, "expected_confidence": 59.49554443359375, "expected_other_confidence": 62.29766845703125, "loss": 1.765625}
{"type": "instruct_eval_sample", "qid": "self_easy_other_hard_57", "question": "What method is used to retrieve the model's parameters in PyTorch: model.parameters(), model.get_parameters(), or model.param_list()?", "model_answer": "B", "correct_answer": "B", "predicted_confidence_letter": "G", "entropy": 0.001861572265625, "expected_confidence": 60.40260314941406, "expected_other_confidence": 64.36126708984375, "loss": 1.8671875}
{"type": "instruct_eval_sample", "qid": "self_easy_other_hard_86", "question": "Which method is used to set the model to evaluation mode: model.eval(), model.test(), or model.evaluate()?", "model_answer": "C", "correct_answer": "C", "predicted_confidence_letter": "C", "entropy": 0.0059814453125, "expected_confidence": 55.222930908203125, "expected_other_confidence": 55.9381103515625, "loss": 1.828125}
{"type": "instruct_eval_sample", "qid": "self_easy_other_hard_67", "question": "To change the learning rate in PyTorch's optimizers, use: optimizer.param_groups[0]['lr'], optimizer.set_lr(), or optimizer.update_lr()?", "model_answer": "A", "correct_answer": "A", "predicted_confidence_letter": "G", "entropy": 0.006805419921875, "expected_confidence": 62.83782958984375, "expected_other_confidence": 54.266357421875, "loss": 1.9921875}
{"type": "instruct_eval_sample", "qid": "self_easy_other_hard_59", "question": "In TensorFlow, which method is used to calculate gradients: tf.gradients(), tf.compute_gradient(), or tf.calc_gradients()?", "model_answer": "D", "correct_answer": "D", "predicted_confidence_letter": "D", "entropy": 0.06103515625, "expected_confidence": 58.424530029296875, "expected_other_confidence": 56.2945556640625, "loss": 1.9140623807907104}
{"type": "instruct_eval_sample", "qid": "self_easy_other_hard_19", "question": "What parameter in Adam optimizer controls the exponential decay rates: beta1, beta, or decay?", "model_answer": "A", "correct_answer": "A", "predicted_confidence_letter": "F", "entropy": 0.67578125, "expected_confidence": 60.909423828125, "expected_other_confidence": 52.4444580078125, "loss": 2.015625}
{"type": "instruct_eval_sample", "qid": "self_easy_other_hard_16", "question": "In TensorFlow, which method is used to compile a model: model.compile(), model.build(), or model.initialize()?", "model_answer": "A", "correct_answer": "A", "predicted_confidence_letter": "G", "entropy": 0.00055694580078125, "expected_confidence": 80.9609603881836, "expected_other_confidence": 73.44192504882812, "loss": 1.1171875}
{"type": "instruct_eval_sample", "qid": "self_easy_other_hard_73", "question": "What is the default optimizer in Keras: SGD, Adam, or RMSprop?", "model_answer": "A", "correct_answer": "A", "predicted_confidence_letter": "G", "entropy": 0.671875, "expected_confidence": 71.61361694335938, "expected_other_confidence": 56.9622802734375, "loss": 2.28125}
{"type": "instruct_eval_sample", "qid": "self_easy_other_hard_53", "question": "What argument specifies the learning rate in Adam optimizer: lr, learning_rate, or rate?", "model_answer": "A", "correct_answer": "C", "predicted_confidence_letter": "F", "entropy": 0.8984375, "expected_confidence": 54.80621337890625, "expected_other_confidence": 49.5159912109375, "loss": 1.8515625}
{"type": "instruct_eval_sample", "qid": "self_easy_other_hard_4", "question": "To concatenate tensors along dim 0, use: torch.cat(), torch.stack(), or torch.concat()?", "model_answer": "D", "correct_answer": "D", "predicted_confidence_letter": "G", "entropy": 0.234375, "expected_confidence": 68.310546875, "expected_other_confidence": 58.07952880859375, "loss": 1.109375}
{"type": "instruct_eval_summary", "mcq_accuracy": 0.7653061224489796, "avg_entropy": 0.2433519071462203, "avg_confidence": 65.25417919548191, "avg_other_confidence": 58.95380214769013, "avg_loss": 1.7438718822537635, "loss_type": "gaussian_soft_bin_ce", "n_samples": 98, "correct_answer_distribution_raw": {"A": 26, "B": 21, "C": 19, "D": 32}, "correct_answer_distribution_pct": {"A": 26.53061224489796, "B": 21.428571428571427, "C": 19.387755102040817, "D": 32.6530612244898}, "predicted_answer_distribution_raw": {"A": 27, "B": 15, "C": 24, "D": 32}, "predicted_answer_distribution_pct": {"A": 27.55102040816326, "B": 15.306122448979592, "C": 24.489795918367346, "D": 32.6530612244898}, "predicted_confidence_distribution_raw": {"A": 0, "B": 0, "C": 6, "D": 16, "E": 0, "F": 9, "G": 67, "H": 0}, "predicted_confidence_distribution_pct": {"A": 0.0, "B": 0.0, "C": 6.122448979591836, "D": 16.3265306122449, "E": 0.0, "F": 9.183673469387756, "G": 68.36734693877551, "H": 0.0}, "predicted_other_confidence_distribution_raw": {"A": 0, "B": 0, "C": 8, "D": 5, "E": 0, "F": 36, "G": 49, "H": 0}, "predicted_other_confidence_distribution_pct": {"A": 0.0, "B": 0.0, "C": 8.16326530612245, "D": 5.1020408163265305, "E": 0.0, "F": 36.734693877551024, "G": 50.0, "H": 0.0}}
{"type": "finetuned_eval_sample", "qid": "self_easy_other_hard_69", "question": "In TensorFlow, which method is used to create a model from layers: tf.Model(), tf.Sequential(), or tf.create_model()?", "model_answer": "D", "correct_answer": "D", "predicted_confidence_letter": "H", "entropy": 0.46875, "expected_confidence": 68.60397338867188, "expected_other_confidence": 56.66046142578125, "loss": 1.5}
{"type": "finetuned_eval_sample", "qid": "self_easy_other_hard_96", "question": "What method is used to shuffle data in a PyTorch DataLoader: shuffle_data(), shuffle(), or randomize()?", "model_answer": "C", "correct_answer": "C", "predicted_confidence_letter": "G", "entropy": 0.44140625, "expected_confidence": 72.50030517578125, "expected_other_confidence": 67.15789794921875, "loss": 1.6796875}
{"type": "finetuned_eval_sample", "qid": "self_easy_other_hard_88", "question": "What method in TensorFlow applies a gradient descent update: optimizer.apply_gradients(), optimizer.update(), or optimizer.step()?", "model_answer": "C", "correct_answer": "A", "predicted_confidence_letter": "H", "entropy": 0.052001953125, "expected_confidence": 78.813232421875, "expected_other_confidence": 67.65327453613281, "loss": 1.0078126192092896}
{"type": "finetuned_eval_sample", "qid": "self_easy_other_hard_11", "question": "In TensorFlow, which function is used to create a placeholder: tf.placeholder(), tf.variable(), or tf.tensor()?", "model_answer": "A", "correct_answer": "A", "predicted_confidence_letter": "H", "entropy": 0.00811767578125, "expected_confidence": 90.57374572753906, "expected_other_confidence": 85.5289306640625, "loss": 0.50390625}
{"type": "finetuned_eval_sample", "qid": "self_easy_other_hard_70", "question": "What is the method to create a linear layer in PyTorch: nn.Linear(), nn.Dense(), or nn.FullyConnected()?", "model_answer": "A", "correct_answer": "A", "predicted_confidence_letter": "H", "entropy": 0.32421875, "expected_confidence": 85.59332275390625, "expected_other_confidence": 76.51241302490234, "loss": 2.013631582260132}
{"type": "finetuned_eval_sample", "qid": "self_easy_other_hard_62", "question": "What function is used to generate random numbers in PyTorch: torch.random(), torch.rand(), or torch.randn()?", "model_answer": "C", "correct_answer": "B", "predicted_confidence_letter": "F", "entropy": 0.60546875, "expected_confidence": 69.10850524902344, "expected_other_confidence": 65.57098388671875, "loss": 1.765625}
{"type": "finetuned_eval_sample", "qid": "self_easy_other_hard_39", "question": "What method is used to detach a tensor from the computation graph in PyTorch: detach(), stop_grad(), or freeze()?", "model_answer": "D", "correct_answer": "D", "predicted_confidence_letter": "H", "entropy": 0.1328125, "expected_confidence": 81.49008178710938, "expected_other_confidence": 74.51339721679688, "loss": 0.9789166450500488}
{"type": "finetuned_eval_sample", "qid": "self_easy_other_hard_75", "question": "What method is used to flatten a tensor in PyTorch: tensor.flatten(), tensor.reshape(), or tensor.view()?", "model_answer": "D", "correct_answer": "C", "predicted_confidence_letter": "H", "entropy": 0.0732421875, "expected_confidence": 83.34506225585938, "expected_other_confidence": 74.30774688720703, "loss": 0.9179695844650269}
{"type": "finetuned_eval_sample", "qid": "self_easy_other_hard_1", "question": "What method moves a PyTorch model to GPU: model.cuda(), model.to('cuda'), or model.gpu()?", "model_answer": "D", "correct_answer": "D", "predicted_confidence_letter": "H", "entropy": 0.55078125, "expected_confidence": 79.19953918457031, "expected_other_confidence": 71.98047637939453, "loss": 1.9203128814697266}
{"type": "finetuned_eval_sample", "qid": "self_easy_other_hard_44", "question": "What's the parameter name for vocabulary size in GPT2Config: vocab_size, n_vocab, or vocabulary_size?", "model_answer": "A", "correct_answer": "A", "predicted_confidence_letter": "H", "entropy": 0.25, "expected_confidence": 80.13870239257812, "expected_other_confidence": 72.38452911376953, "loss": 1.1640626192092896}
{"type": "finetuned_eval_sample", "qid": "self_easy_other_hard_64", "question": "In TensorFlow, what is the correct way to create a dataset from a numpy array: tf.data.Dataset.from_tensor_slices(), tf.data.Dataset.from_array(), or tf.data.Dataset.from_numpy()?", "model_answer": "A", "correct_answer": "A", "predicted_confidence_letter": "H", "entropy": 0.31640625, "expected_confidence": 83.41899108886719, "expected_other_confidence": 73.02421569824219, "loss": 1.6614155769348145}
{"type": "finetuned_eval_sample", "qid": "self_easy_other_hard_81", "question": "What method is used to load a pre-trained model in Hugging Face Transformers: from_pretrained(), load_model(), or import_model()?", "model_answer": "D", "correct_answer": "D", "predicted_confidence_letter": "H", "entropy": 0.00823974609375, "expected_confidence": 88.3183364868164, "expected_other_confidence": 83.41033935546875, "loss": 0.53125}
{"type": "finetuned_eval_sample", "qid": "self_easy_other_hard_78", "question": "What parameter specifies the batch size in Keras fit method: batch_size, size, or batch?", "model_answer": "C", "correct_answer": "C", "predicted_confidence_letter": "H", "entropy": 0.08544921875, "expected_confidence": 87.65750122070312, "expected_other_confidence": 77.33634948730469, "loss": 0.6406506299972534}
{"type": "finetuned_eval_sample", "qid": "self_easy_other_hard_17", "question": "What is the return type of torch.split() in PyTorch: tuple, list, or tensor?", "model_answer": "D", "correct_answer": "D", "predicted_confidence_letter": "G", "entropy": 0.24609375, "expected_confidence": 77.21855163574219, "expected_other_confidence": 71.30115509033203, "loss": 1.1640625}
{"type": "finetuned_eval_sample", "qid": "self_easy_other_hard_56", "question": "What is the parameter name for the number of attention heads in BertConfig: num_attention_heads, attention_heads, or n_heads?", "model_answer": "C", "correct_answer": "C", "predicted_confidence_letter": "H", "entropy": 0.94921875, "expected_confidence": 75.14507293701172, "expected_other_confidence": 72.51495361328125, "loss": 2.734375}
{"type": "finetuned_eval_sample", "qid": "self_easy_other_hard_66", "question": "What is the return type of model.forward() in PyTorch: Tensor, List, or Dict?", "model_answer": "A", "correct_answer": "A", "predicted_confidence_letter": "H", "entropy": 0.1396484375, "expected_confidence": 77.85452270507812, "expected_other_confidence": 65.76934814453125, "loss": 1.206766128540039}
{"type": "finetuned_eval_sample", "qid": "self_easy_other_hard_28", "question": "What class is used for linear layers in PyTorch: nn.Linear, nn.Dense, or nn.FullyConnected?", "model_answer": "B", "correct_answer": "B", "predicted_confidence_letter": "H", "entropy": 0.2314453125, "expected_confidence": 83.80870819091797, "expected_other_confidence": 71.78596496582031, "loss": 1.0937498807907104}
{"type": "finetuned_eval_sample", "qid": "self_easy_other_hard_55", "question": "What function in PyTorch is used for dropout: torch.dropout(), torch.nn.Dropout(), or torch.dropout_layer()?", "model_answer": "B", "correct_answer": "B", "predicted_confidence_letter": "H", "entropy": 1.0546875, "expected_confidence": 77.28153228759766, "expected_other_confidence": 72.33161926269531, "loss": 2.9417433738708496}
{"type": "finetuned_eval_sample", "qid": "self_easy_other_hard_30", "question": "What method in sklearn is used to fit a model: fit_model(), train(), or fit()?", "model_answer": "C", "correct_answer": "C", "predicted_confidence_letter": "H", "entropy": 0.00494384765625, "expected_confidence": 83.07637023925781, "expected_other_confidence": 73.15170288085938, "loss": 0.83203125}
{"type": "finetuned_eval_sample", "qid": "self_easy_other_hard_60", "question": "What is the parameter name for the dropout probability in nn.Dropout: p, dropout_prob, or drop_prob?", "model_answer": "A", "correct_answer": "A", "predicted_confidence_letter": "H", "entropy": 0.7578125, "expected_confidence": 82.54598999023438, "expected_other_confidence": 68.1656265258789, "loss": 2.71875}
{"type": "finetuned_eval_sample", "qid": "self_easy_other_hard_87", "question": "What argument is used to specify the batch size in PyTorch's DataLoader: batch_size, size, or batch_sz?", "model_answer": "B", "correct_answer": "B", "predicted_confidence_letter": "H", "entropy": 0.12353515625, "expected_confidence": 84.92122650146484, "expected_other_confidence": 72.57392883300781, "loss": 0.8008183836936951}
{"type": "finetuned_eval_sample", "qid": "self_easy_other_hard_12", "question": "What method is used to load a model in PyTorch: model.load(), torch.load_model(), or torch.load()?", "model_answer": "C", "correct_answer": "C", "predicted_confidence_letter": "F", "entropy": 1.1796875, "expected_confidence": 58.60076904296875, "expected_other_confidence": 61.16119384765625, "loss": 2.719080924987793}
{"type": "finetuned_eval_sample", "qid": "self_easy_other_hard_31", "question": "In PyTorch, what method is used to perform a forward pass: model.forward(), model(), or model.predict()?", "model_answer": "A", "correct_answer": "D", "predicted_confidence_letter": "H", "entropy": 0.5703125, "expected_confidence": 88.29498291015625, "expected_other_confidence": 80.94951629638672, "loss": 3.6072838306427}
{"type": "finetuned_eval_sample", "qid": "self_easy_other_hard_71", "question": "What method is used to set the seed for random number generation in PyTorch: torch.manual_seed(), torch.set_seed(), or torch.random_seed()?", "model_answer": "C", "correct_answer": "C", "predicted_confidence_letter": "H", "entropy": 0.466796875, "expected_confidence": 86.84268188476562, "expected_other_confidence": 78.52914428710938, "loss": 2.578125}
{"type": "finetuned_eval_sample", "qid": "self_easy_other_hard_47", "question": "What is the method to load a pretrained model in Hugging Face Transformers: from_pretrained(), load_model(), or load_pretrained()?", "model_answer": "A", "correct_answer": "A", "predicted_confidence_letter": "H", "entropy": 0.01031494140625, "expected_confidence": 88.94389343261719, "expected_other_confidence": 80.73554229736328, "loss": 0.5234375}
{"type": "finetuned_eval_sample", "qid": "self_easy_other_hard_6", "question": "Does model.eval() disable dropout: yes, no, or only in training mode?", "model_answer": "A", "correct_answer": "B", "predicted_confidence_letter": "E", "entropy": 1.125, "expected_confidence": 54.157562255859375, "expected_other_confidence": 50.69366455078125, "loss": 2.4531235694885254}
{"type": "finetuned_eval_sample", "qid": "self_easy_other_hard_15", "question": "In Keras, what argument of fit() specifies the number of epochs: epochs, num_epochs, or iterations?", "model_answer": "D", "correct_answer": "D", "predicted_confidence_letter": "H", "entropy": 0.1474609375, "expected_confidence": 80.47293090820312, "expected_other_confidence": 77.12632751464844, "loss": 1.1703346967697144}
{"type": "finetuned_eval_sample", "qid": "self_easy_other_hard_80", "question": "What method do you call to compute gradients in PyTorch: loss.backward(), loss.grad(), or loss.compute_grad()?", "model_answer": "A", "correct_answer": "A", "predicted_confidence_letter": "H", "entropy": 0.00347900390625, "expected_confidence": 87.75062561035156, "expected_other_confidence": 80.1650619506836, "loss": 0.61328125}
{"type": "finetuned_eval_sample", "qid": "self_easy_other_hard_91", "question": "What method in PyTorch concatenates tensors along a specified dimension: torch.concat(), torch.join(), or torch.cat()?", "model_answer": "D", "correct_answer": "D", "predicted_confidence_letter": "H", "entropy": 0.11767578125, "expected_confidence": 87.0232162475586, "expected_other_confidence": 78.04464721679688, "loss": 0.7165228128433228}
{"type": "finetuned_eval_sample", "qid": "self_easy_other_hard_10", "question": "What parameter controls the dropout rate in nn.Dropout: p, rate, or dropout_rate?", "model_answer": "B", "correct_answer": "A", "predicted_confidence_letter": "F", "entropy": 0.83984375, "expected_confidence": 68.18367004394531, "expected_other_confidence": 57.56927490234375, "loss": 2.1929101943969727}
{"type": "finetuned_eval_sample", "qid": "self_easy_other_hard_40", "question": "What method moves a PyTorch model to GPU: model.cuda(), model.to('cuda'), or model.gpu()?", "model_answer": "D", "correct_answer": "C", "predicted_confidence_letter": "H", "entropy": 0.328125, "expected_confidence": 83.58580017089844, "expected_other_confidence": 76.57081604003906, "loss": 1.9477037191390991}
{"type": "finetuned_eval_sample", "qid": "self_easy_other_hard_29", "question": "What function is used to apply a softmax operation in PyTorch: torch.softmax(), torch.nn.softmax(), or nn.softmax()?", "model_answer": "C", "correct_answer": "B", "predicted_confidence_letter": "H", "entropy": 0.484375, "expected_confidence": 81.65416717529297, "expected_other_confidence": 75.41114807128906, "loss": 1.828125}
{"type": "finetuned_eval_sample", "qid": "self_easy_other_hard_27", "question": "What method is used to compute the loss in PyTorch: loss_fn(), compute_loss(), or loss()?", "model_answer": "C", "correct_answer": "B", "predicted_confidence_letter": "H", "entropy": 0.921875, "expected_confidence": 69.95109558105469, "expected_other_confidence": 54.376220703125, "loss": 2.34375}
{"type": "finetuned_eval_sample", "qid": "self_easy_other_hard_84", "question": "What function is used to create a tensor from a NumPy array in PyTorch: torch.from_numpy(), torch.tensor(), or torch.as_tensor()?", "model_answer": "C", "correct_answer": "B", "predicted_confidence_letter": "H", "entropy": 0.9375, "expected_confidence": 80.81695556640625, "expected_other_confidence": 74.24209594726562, "loss": 4.28125}
{"type": "finetuned_eval_sample", "qid": "self_easy_other_hard_89", "question": "What is the default activation function in Keras Dense layers: relu, sigmoid, or linear?", "model_answer": "D", "correct_answer": "B", "predicted_confidence_letter": "H", "entropy": 0.1396484375, "expected_confidence": 76.70111083984375, "expected_other_confidence": 74.68162536621094, "loss": 1.2124929428100586}
{"type": "finetuned_eval_sample", "qid": "self_easy_other_hard_48", "question": "What method is used to compute the loss in PyTorch: loss_fn(), compute_loss(), or cross_entropy()?", "model_answer": "A", "correct_answer": "C", "predicted_confidence_letter": "F", "entropy": 1.140625, "expected_confidence": 62.58186340332031, "expected_other_confidence": 54.22271728515625, "loss": 3.046877384185791}
{"type": "finetuned_eval_sample", "qid": "self_easy_other_hard_25", "question": "What method is used to add a layer to a Sequential model in Keras: model.add(), model.insert(), or model.append()?", "model_answer": "B", "correct_answer": "B", "predicted_confidence_letter": "H", "entropy": 0.005096435546875, "expected_confidence": 88.57683563232422, "expected_other_confidence": 84.99244689941406, "loss": 0.61328125}
{"type": "finetuned_eval_sample", "qid": "self_easy_other_hard_2", "question": "Does tokenizer.encode() return a list or tensor in Hugging Face Transformers?", "model_answer": "A", "correct_answer": "A", "predicted_confidence_letter": "H", "entropy": 0.67578125, "expected_confidence": 77.24151611328125, "expected_other_confidence": 67.7471923828125, "loss": 1.9609375}
{"type": "finetuned_eval_sample", "qid": "self_easy_other_hard_46", "question": "To freeze parameters: param.requires_grad = False or param.freeze()?", "model_answer": "D", "correct_answer": "D", "predicted_confidence_letter": "H", "entropy": 0.244140625, "expected_confidence": 71.16626739501953, "expected_other_confidence": 63.74847412109375, "loss": 1.484375}
{"type": "finetuned_eval_sample", "qid": "self_easy_other_hard_97", "question": "What does model.parameters() return in PyTorch: list of parameters, dict of parameters, or a tensor?", "model_answer": "D", "correct_answer": "D", "predicted_confidence_letter": "H", "entropy": 0.1474609375, "expected_confidence": 79.7638931274414, "expected_other_confidence": 71.99880981445312, "loss": 1.1351232528686523}
{"type": "finetuned_eval_sample", "qid": "self_easy_other_hard_45", "question": "Does model.eval() disable dropout: yes, no, or only in training mode?", "model_answer": "C", "correct_answer": "A", "predicted_confidence_letter": "E", "entropy": 1.015625, "expected_confidence": 53.89625549316406, "expected_other_confidence": 50.51300048828125, "loss": 1.5546873807907104}
{"type": "finetuned_eval_sample", "qid": "self_easy_other_hard_95", "question": "Which function is used to convert a PyTorch tensor to a NumPy array: tensor.numpy(), tensor.as_numpy(), or tensor.to_numpy()?", "model_answer": "B", "correct_answer": "B", "predicted_confidence_letter": "H", "entropy": 0.0458984375, "expected_confidence": 85.5509262084961, "expected_other_confidence": 76.73118591308594, "loss": 0.77734375}
{"type": "finetuned_eval_sample", "qid": "self_easy_other_hard_37", "question": "In TensorFlow, what method is used to evaluate a model: model.evaluate(), model.test(), or model.score()?", "model_answer": "B", "correct_answer": "B", "predicted_confidence_letter": "H", "entropy": 0.07568359375, "expected_confidence": 86.29342651367188, "expected_other_confidence": 79.4488525390625, "loss": 0.7265654802322388}
{"type": "finetuned_eval_sample", "qid": "self_easy_other_hard_23", "question": "What method is used to generate random numbers in NumPy: np.random(), np.rand(), or np.random_numbers()?", "model_answer": "A", "correct_answer": "A", "predicted_confidence_letter": "H", "entropy": 0.00238037109375, "expected_confidence": 87.1099624633789, "expected_other_confidence": 79.83268737792969, "loss": 0.6640625}
{"type": "finetuned_eval_sample", "qid": "self_easy_other_hard_85", "question": "What method is used to save a PyTorch model: model.save(), torch.save(), or model.serialize()?", "model_answer": "D", "correct_answer": "D", "predicted_confidence_letter": "H", "entropy": 0.26171875, "expected_confidence": 83.5079116821289, "expected_other_confidence": 77.73998260498047, "loss": 1.0703151226043701}
{"type": "finetuned_eval_sample", "qid": "self_easy_other_hard_82", "question": "What is the return type of model.forward() in PyTorch: tensor, list, or dict?", "model_answer": "D", "correct_answer": "D", "predicted_confidence_letter": "H", "entropy": 0.033203125, "expected_confidence": 84.66483306884766, "expected_other_confidence": 76.42959594726562, "loss": 0.7578125}
{"type": "finetuned_eval_sample", "qid": "self_easy_other_hard_74", "question": "What is the method to get the shape of a tensor in PyTorch: tensor.shape(), tensor.size(), or tensor.dim()?", "model_answer": "C", "correct_answer": "D", "predicted_confidence_letter": "H", "entropy": 0.119140625, "expected_confidence": 83.69286346435547, "expected_other_confidence": 75.62995910644531, "loss": 0.9060691595077515}
{"type": "finetuned_eval_sample", "qid": "self_easy_other_hard_65", "question": "What is the name of the method to apply the ReLU activation function in PyTorch: torch.ReLU(), nn.ReLU(), or torch.activation.ReLU()?", "model_answer": "C", "correct_answer": "D", "predicted_confidence_letter": "H", "entropy": 0.9296875, "expected_confidence": 75.58109283447266, "expected_other_confidence": 69.87205505371094, "loss": 2.890625}
{"type": "finetuned_eval_sample", "qid": "self_easy_other_hard_68", "question": "What is the default value of num_return_sequences in Hugging Face Transformers: 1, 0, or None?", "model_answer": "D", "correct_answer": "D", "predicted_confidence_letter": "H", "entropy": 0.921875, "expected_confidence": 78.75972747802734, "expected_other_confidence": 73.02688598632812, "loss": 2.78125}
{"type": "finetuned_eval_sample", "qid": "self_easy_other_hard_7", "question": "To freeze parameters: param.requires_grad = False or param.freeze()?", "model_answer": "D", "correct_answer": "D", "predicted_confidence_letter": "H", "entropy": 0.09765625, "expected_confidence": 72.83462524414062, "expected_other_confidence": 64.83238220214844, "loss": 1.1876543760299683}
{"type": "finetuned_eval_sample", "qid": "self_easy_other_hard_18", "question": "What function is used to create a tensor in NumPy: np.array(), np.tensor(), or np.create()?", "model_answer": "D", "correct_answer": "D", "predicted_confidence_letter": "H", "entropy": 0.06884765625, "expected_confidence": 82.12554168701172, "expected_other_confidence": 75.87116241455078, "loss": 0.8398450016975403}
{"type": "finetuned_eval_sample", "qid": "self_easy_other_hard_58", "question": "To convert a tensor to a NumPy array in PyTorch, use: tensor.numpy(), tensor.as_numpy(), or tensor.to_numpy()?", "model_answer": "D", "correct_answer": "D", "predicted_confidence_letter": "H", "entropy": 0.02294921875, "expected_confidence": 83.5267562866211, "expected_other_confidence": 74.91365051269531, "loss": 0.84765625}
{"type": "finetuned_eval_sample", "qid": "self_easy_other_hard_43", "question": "To concatenate tensors along dim 0, use: torch.cat(), torch.stack(), or torch.concat()?", "model_answer": "A", "correct_answer": "A", "predicted_confidence_letter": "H", "entropy": 0.67578125, "expected_confidence": 83.03229522705078, "expected_other_confidence": 70.67794799804688, "loss": 2.59375}
{"type": "finetuned_eval_sample", "qid": "self_easy_other_hard_35", "question": "What method is used to clear gradients in PyTorch: optimizer.clear_grad(), optimizer.zero_grad(), or optimizer.reset_grad()?", "model_answer": "A", "correct_answer": "A", "predicted_confidence_letter": "F", "entropy": 0.056884765625, "expected_confidence": 71.00074768066406, "expected_other_confidence": 57.60711669921875, "loss": 1.46875}
{"type": "finetuned_eval_sample", "qid": "self_easy_other_hard_32", "question": "What attribute in the optimizer defines learning rates in PyTorch: lr, learning_rate, or rate?", "model_answer": "D", "correct_answer": "D", "predicted_confidence_letter": "H", "entropy": 0.150390625, "expected_confidence": 79.23446655273438, "expected_other_confidence": 69.13124084472656, "loss": 1.1915628910064697}
{"type": "finetuned_eval_sample", "qid": "self_easy_other_hard_24", "question": "What attribute of nn.Module checks if the model is in evaluation mode: .is_eval(), .eval_mode(), or .training?", "model_answer": "D", "correct_answer": "D", "predicted_confidence_letter": "G", "entropy": 0.04541015625, "expected_confidence": 74.89701080322266, "expected_other_confidence": 53.0047607421875, "loss": 1.25}
{"type": "finetuned_eval_sample", "qid": "self_easy_other_hard_93", "question": "What method in TensorFlow's Keras API compiles a model: model.compile_model(), model.compile(), or model.build()?", "model_answer": "A", "correct_answer": "A", "predicted_confidence_letter": "H", "entropy": 0.03076171875, "expected_confidence": 88.15045166015625, "expected_other_confidence": 74.20722961425781, "loss": 0.59375}
{"type": "finetuned_eval_sample", "qid": "self_easy_other_hard_22", "question": "To create a dataset in PyTorch, which class is used: Dataset, DataLoader, or DataSet?", "model_answer": "D", "correct_answer": "D", "predicted_confidence_letter": "H", "entropy": 0.06005859375, "expected_confidence": 81.29594421386719, "expected_other_confidence": 74.6872329711914, "loss": 0.9023439288139343}
{"type": "finetuned_eval_sample", "qid": "self_easy_other_hard_34", "question": "What method is used to shuffle data in PyTorch DataLoader: shuffle_data(), randomize(), or shuffle()?", "model_answer": "B", "correct_answer": "B", "predicted_confidence_letter": "G", "entropy": 0.0576171875, "expected_confidence": 72.43324279785156, "expected_other_confidence": 60.89141845703125, "loss": 1.3359375}
{"type": "finetuned_eval_sample", "qid": "self_easy_other_hard_90", "question": "What method is used to initialize weights in a Keras layer: layer.initialize_weights(), layer.build(), or layer.kernel_initializer?", "model_answer": "D", "correct_answer": "A", "predicted_confidence_letter": "F", "entropy": 0.435546875, "expected_confidence": 66.68121337890625, "expected_other_confidence": 59.98016357421875, "loss": 1.515625}
{"type": "finetuned_eval_sample", "qid": "self_easy_other_hard_21", "question": "What method is used to save a model in PyTorch: model.save(), torch.save(), or model.store()?", "model_answer": "B", "correct_answer": "B", "predicted_confidence_letter": "H", "entropy": 0.35546875, "expected_confidence": 79.21939849853516, "expected_other_confidence": 72.16766357421875, "loss": 1.7265605926513672}
{"type": "finetuned_eval_sample", "qid": "self_easy_other_hard_26", "question": "What parameter specifies the batch size in DataLoader: batch_size, size, or num_samples?", "model_answer": "D", "correct_answer": "D", "predicted_confidence_letter": "H", "entropy": 0.11376953125, "expected_confidence": 80.68492889404297, "expected_other_confidence": 74.84683990478516, "loss": 0.9129927158355713}
{"type": "finetuned_eval_sample", "qid": "self_easy_other_hard_49", "question": "What is the default value of return_dict in Hugging Face Transformers model forward methods: True, False, or None?", "model_answer": "C", "correct_answer": "D", "predicted_confidence_letter": "H", "entropy": 0.4453125, "expected_confidence": 66.5277099609375, "expected_other_confidence": 54.97314453125, "loss": 1.6640625}
{"type": "finetuned_eval_sample", "qid": "self_easy_other_hard_5", "question": "What's the parameter name for vocabulary size in GPT2Config: vocab_size, n_vocab, or vocabulary_size?", "model_answer": "C", "correct_answer": "C", "predicted_confidence_letter": "H", "entropy": 0.703125, "expected_confidence": 79.68978881835938, "expected_other_confidence": 71.92405700683594, "loss": 2.328125}
{"type": "finetuned_eval_sample", "qid": "self_easy_other_hard_98", "question": "What parameter specifies the optimizer's momentum in PyTorch: momentum, beta, or speed?", "model_answer": "B", "correct_answer": "B", "predicted_confidence_letter": "F", "entropy": 0.61328125, "expected_confidence": 66.56105041503906, "expected_other_confidence": 57.43804931640625, "loss": 1.6484375}
{"type": "finetuned_eval_sample", "qid": "self_easy_other_hard_3", "question": "What attribute stores hidden size in BertConfig: hidden_size, d_model, or embedding_dim?", "model_answer": "C", "correct_answer": "B", "predicted_confidence_letter": "H", "entropy": 1.015625, "expected_confidence": 68.10066223144531, "expected_other_confidence": 57.396240234375, "loss": 2.1875}
{"type": "finetuned_eval_sample", "qid": "self_easy_other_hard_41", "question": "Does tokenizer.encode() return a list or tensor in Hugging Face Transformers?", "model_answer": "C", "correct_answer": "A", "predicted_confidence_letter": "H", "entropy": 0.3203125, "expected_confidence": 81.57428741455078, "expected_other_confidence": 67.11135864257812, "loss": 1.6222268342971802}
{"type": "finetuned_eval_sample", "qid": "self_easy_other_hard_83", "question": "What attribute in torch.optim.Adam stores the learning rate: lr, learning_rate, or alpha?", "model_answer": "B", "correct_answer": "B", "predicted_confidence_letter": "H", "entropy": 0.466796875, "expected_confidence": 80.7265853881836, "expected_other_confidence": 72.46055603027344, "loss": 1.8125}
{"type": "finetuned_eval_sample", "qid": "self_easy_other_hard_79", "question": "What method is used to generate predictions with a model in PyTorch: model.predict(), model.forward(), or model.call()?", "model_answer": "D", "correct_answer": "D", "predicted_confidence_letter": "H", "entropy": 0.41015625, "expected_confidence": 76.69090270996094, "expected_other_confidence": 70.8551025390625, "loss": 1.5234375}
{"type": "finetuned_eval_sample", "qid": "self_easy_other_hard_61", "question": "What method is used to initialize weights in PyTorch: torch.init(), torch.weight_init(), or torch.initialize_weights()?", "model_answer": "C", "correct_answer": "C", "predicted_confidence_letter": "H", "entropy": 0.05126953125, "expected_confidence": 80.17250061035156, "expected_other_confidence": 66.05712890625, "loss": 0.9453125596046448}
{"type": "finetuned_eval_sample", "qid": "self_easy_other_hard_33", "question": "What argument in nn.Conv2d specifies the number of output channels: out_channels, num_output, or n_out?", "model_answer": "A", "correct_answer": "A", "predicted_confidence_letter": "H", "entropy": 0.00909423828125, "expected_confidence": 83.03040313720703, "expected_other_confidence": 71.07940673828125, "loss": 0.80859375}
{"type": "finetuned_eval_sample", "qid": "self_easy_other_hard_77", "question": "What method is used to evaluate a model in Keras: model.evaluate(), model.test(), or model.val()?", "model_answer": "A", "correct_answer": "A", "predicted_confidence_letter": "H", "entropy": 0.01806640625, "expected_confidence": 89.18885040283203, "expected_other_confidence": 81.34774017333984, "loss": 0.58203125}
{"type": "finetuned_eval_sample", "qid": "self_easy_other_hard_9", "question": "What is the default learning rate for Adam optimizer in PyTorch: 0.001, 0.01, or 0.1?", "model_answer": "C", "correct_answer": "C", "predicted_confidence_letter": "F", "entropy": 0.765625, "expected_confidence": 64.37217712402344, "expected_other_confidence": 58.7713623046875, "loss": 1.703125}
{"type": "finetuned_eval_sample", "qid": "self_easy_other_hard_54", "question": "What method in PyTorch is used to set a model to training mode: model.train(), model.set_train(), or model.switch_to_train()?", "model_answer": "D", "correct_answer": "D", "predicted_confidence_letter": "H", "entropy": 0.05029296875, "expected_confidence": 83.06367492675781, "expected_other_confidence": 76.37786865234375, "loss": 0.84375}
{"type": "finetuned_eval_sample", "qid": "self_easy_other_hard_51", "question": "What is the correct way to initialize a TensorFlow variable: tf.Variable(value), tf.Tensor(value), or tf.create_variable(value)?", "model_answer": "A", "correct_answer": "A", "predicted_confidence_letter": "G", "entropy": 0.11669921875, "expected_confidence": 83.72298431396484, "expected_other_confidence": 77.24334716796875, "loss": 0.95703125}
{"type": "finetuned_eval_sample", "qid": "self_easy_other_hard_14", "question": "What method is used for backpropagation in TensorFlow: loss.backprop(), loss.backward(), or loss.grad()?", "model_answer": "D", "correct_answer": "D", "predicted_confidence_letter": "H", "entropy": 0.029296875, "expected_confidence": 76.39446258544922, "expected_other_confidence": 67.61802673339844, "loss": 1.125}
{"type": "finetuned_eval_sample", "qid": "self_easy_other_hard_94", "question": "What attribute in TensorFlow's optimizer controls the learning rate decay: learning_rate, lr_schedule, or decay_rate?", "model_answer": "A", "correct_answer": "C", "predicted_confidence_letter": "H", "entropy": 0.404296875, "expected_confidence": 66.82876586914062, "expected_other_confidence": 58.39263916015625, "loss": 1.59375}
{"type": "finetuned_eval_sample", "qid": "self_easy_other_hard_92", "question": "What parameter in the LSTM class specifies the number of layers: num_layers, layers, or n_layers?", "model_answer": "B", "correct_answer": "B", "predicted_confidence_letter": "F", "entropy": 0.6484375, "expected_confidence": 59.877777099609375, "expected_other_confidence": 60.37506103515625, "loss": 1.6875}
{"type": "finetuned_eval_sample", "qid": "self_easy_other_hard_13", "question": "What method is used to set the model to training mode in PyTorch: model.train(), model.training(), or model.set_train()?", "model_answer": "C", "correct_answer": "C", "predicted_confidence_letter": "G", "entropy": 0.1865234375, "expected_confidence": 80.61114501953125, "expected_other_confidence": 73.46782684326172, "loss": 1.0234596729278564}
{"type": "finetuned_eval_sample", "qid": "self_easy_other_hard_72", "question": "What is the method to perform backpropagation in TensorFlow: model.backpropagate(), model.backward(), or model.fit()?", "model_answer": "A", "correct_answer": "A", "predicted_confidence_letter": "H", "entropy": 0.2119140625, "expected_confidence": 72.9949951171875, "expected_other_confidence": 71.82632446289062, "loss": 1.5781240463256836}
{"type": "finetuned_eval_sample", "qid": "self_easy_other_hard_38", "question": "What function is used to convert a list to a tensor in PyTorch: torch.tensor(), torch.from_list(), or torch.as_tensor()?", "model_answer": "C", "correct_answer": "C", "predicted_confidence_letter": "H", "entropy": 0.79296875, "expected_confidence": 83.3309326171875, "expected_other_confidence": 76.30294799804688, "loss": 2.9218764305114746}
{"type": "finetuned_eval_sample", "qid": "self_easy_other_hard_50", "question": "In TensorFlow, what method is used to compile a model: model.compile(), model.setup(), or model.build()?", "model_answer": "D", "correct_answer": "D", "predicted_confidence_letter": "H", "entropy": 0.08740234375, "expected_confidence": 88.77982330322266, "expected_other_confidence": 85.90131378173828, "loss": 0.5547361373901367}
{"type": "finetuned_eval_sample", "qid": "self_easy_other_hard_63", "question": "What is the method to create a tensor filled with zeros in PyTorch: torch.zeros_like(), torch.zeros(), or torch.empty()?", "model_answer": "D", "correct_answer": "D", "predicted_confidence_letter": "H", "entropy": 0.76171875, "expected_confidence": 82.07573699951172, "expected_other_confidence": 72.12547302246094, "loss": 2.671875}
{"type": "finetuned_eval_sample", "qid": "self_easy_other_hard_42", "question": "What attribute stores hidden size in BertConfig: hidden_size, d_model, or embedding_dim?", "model_answer": "D", "correct_answer": "D", "predicted_confidence_letter": "H", "entropy": 0.75, "expected_confidence": 76.01444244384766, "expected_other_confidence": 55.9375, "loss": 2.125}
{"type": "finetuned_eval_sample", "qid": "self_easy_other_hard_20", "question": "What attribute of a PyTorch tensor gives the shape: .size(), .shape(), or .dim()?", "model_answer": "B", "correct_answer": "B", "predicted_confidence_letter": "H", "entropy": 0.322265625, "expected_confidence": 82.04375457763672, "expected_other_confidence": 70.98320007324219, "loss": 1.7981723546981812}
{"type": "finetuned_eval_sample", "qid": "self_easy_other_hard_36", "question": "What method is used to flatten a tensor in PyTorch: flatten(), view(), or reshape()?", "model_answer": "C", "correct_answer": "C", "predicted_confidence_letter": "H", "entropy": 0.6875, "expected_confidence": 77.8531494140625, "expected_other_confidence": 73.00289154052734, "loss": 2.125}
{"type": "finetuned_eval_sample", "qid": "self_easy_other_hard_52", "question": "What method is used to save a model in TensorFlow: model.save(), model.store(), or model.persist()?", "model_answer": "C", "correct_answer": "C", "predicted_confidence_letter": "H", "entropy": 0.0084228515625, "expected_confidence": 88.5737533569336, "expected_other_confidence": 84.17613983154297, "loss": 0.5703125}
{"type": "finetuned_eval_sample", "qid": "self_easy_other_hard_76", "question": "What is the return type of model.predict() in Keras: Numpy array, Tensor, or List?", "model_answer": "D", "correct_answer": "D", "predicted_confidence_letter": "H", "entropy": 0.07666015625, "expected_confidence": 75.53907775878906, "expected_other_confidence": 64.13070678710938, "loss": 1.140628457069397}
{"type": "finetuned_eval_sample", "qid": "self_easy_other_hard_8", "question": "What method is used to initialize weights in PyTorch: torch.init(), torch.weight_init(), or torch.nn.init()?", "model_answer": "B", "correct_answer": "B", "predicted_confidence_letter": "H", "entropy": 0.03271484375, "expected_confidence": 81.28164672851562, "expected_other_confidence": 71.17729187011719, "loss": 0.921875}
{"type": "finetuned_eval_sample", "qid": "self_easy_other_hard_57", "question": "What method is used to retrieve the model's parameters in PyTorch: model.parameters(), model.get_parameters(), or model.param_list()?", "model_answer": "B", "correct_answer": "B", "predicted_confidence_letter": "G", "entropy": 0.018798828125, "expected_confidence": 86.42981719970703, "expected_other_confidence": 81.86084747314453, "loss": 0.8984375}
{"type": "finetuned_eval_sample", "qid": "self_easy_other_hard_86", "question": "Which method is used to set the model to evaluation mode: model.eval(), model.test(), or model.evaluate()?", "model_answer": "C", "correct_answer": "C", "predicted_confidence_letter": "H", "entropy": 0.00823974609375, "expected_confidence": 87.93148040771484, "expected_other_confidence": 77.27958679199219, "loss": 0.58203125}
{"type": "finetuned_eval_sample", "qid": "self_easy_other_hard_67", "question": "To change the learning rate in PyTorch's optimizers, use: optimizer.param_groups[0]['lr'], optimizer.set_lr(), or optimizer.update_lr()?", "model_answer": "A", "correct_answer": "A", "predicted_confidence_letter": "H", "entropy": 0.034423828125, "expected_confidence": 74.34837341308594, "expected_other_confidence": 63.79638671875, "loss": 1.2109375}
{"type": "finetuned_eval_sample", "qid": "self_easy_other_hard_59", "question": "In TensorFlow, which method is used to calculate gradients: tf.gradients(), tf.compute_gradient(), or tf.calc_gradients()?", "model_answer": "D", "correct_answer": "D", "predicted_confidence_letter": "H", "entropy": 0.078125, "expected_confidence": 85.5635757446289, "expected_other_confidence": 77.6779556274414, "loss": 0.7109443545341492}
{"type": "finetuned_eval_sample", "qid": "self_easy_other_hard_19", "question": "What parameter in Adam optimizer controls the exponential decay rates: beta1, beta, or decay?", "model_answer": "A", "correct_answer": "A", "predicted_confidence_letter": "D", "entropy": 0.9609375, "expected_confidence": 39.6649169921875, "expected_other_confidence": 41.0772705078125, "loss": 1.0234375}
{"type": "finetuned_eval_sample", "qid": "self_easy_other_hard_16", "question": "In TensorFlow, which method is used to compile a model: model.compile(), model.build(), or model.initialize()?", "model_answer": "A", "correct_answer": "A", "predicted_confidence_letter": "H", "entropy": 0.007781982421875, "expected_confidence": 89.6275634765625, "expected_other_confidence": 85.06773376464844, "loss": 0.56640625}
{"type": "finetuned_eval_sample", "qid": "self_easy_other_hard_73", "question": "What is the default optimizer in Keras: SGD, Adam, or RMSprop?", "model_answer": "A", "correct_answer": "A", "predicted_confidence_letter": "D", "entropy": 0.90625, "expected_confidence": 52.010955810546875, "expected_other_confidence": 52.39349365234375, "loss": 1.53125}
{"type": "finetuned_eval_sample", "qid": "self_easy_other_hard_53", "question": "What argument specifies the learning rate in Adam optimizer: lr, learning_rate, or rate?", "model_answer": "D", "correct_answer": "C", "predicted_confidence_letter": "E", "entropy": 1.1875, "expected_confidence": 59.083251953125, "expected_other_confidence": 45.8843994140625, "loss": 2.798752546310425}
{"type": "finetuned_eval_sample", "qid": "self_easy_other_hard_4", "question": "To concatenate tensors along dim 0, use: torch.cat(), torch.stack(), or torch.concat()?", "model_answer": "D", "correct_answer": "D", "predicted_confidence_letter": "H", "entropy": 0.41015625, "expected_confidence": 83.34800720214844, "expected_other_confidence": 71.76021575927734, "loss": 2.03125}
{"type": "finetuned_eval_summary", "mcq_accuracy": 0.7857142857142857, "avg_entropy": 0.3620798539142219, "avg_confidence": 78.06862975140007, "avg_other_confidence": 70.03974330668547, "avg_loss": 1.4950775716985976, "loss_type": "gaussian_soft_bin_ce", "n_samples": 98, "correct_answer_distribution_raw": {"A": 26, "B": 21, "C": 19, "D": 32}, "correct_answer_distribution_pct": {"A": 26.53061224489796, "B": 21.428571428571427, "C": 19.387755102040817, "D": 32.6530612244898}, "predicted_answer_distribution_raw": {"A": 25, "B": 15, "C": 25, "D": 33}, "predicted_answer_distribution_pct": {"A": 25.510204081632654, "B": 15.306122448979592, "C": 25.510204081632654, "D": 33.6734693877551}, "predicted_confidence_distribution_raw": {"A": 0, "B": 0, "C": 0, "D": 2, "E": 3, "F": 9, "G": 7, "H": 77}, "predicted_confidence_distribution_pct": {"A": 0.0, "B": 0.0, "C": 0.0, "D": 2.0408163265306123, "E": 3.061224489795918, "F": 9.183673469387756, "G": 7.142857142857142, "H": 78.57142857142857}, "predicted_other_confidence_distribution_raw": {"A": 0, "B": 0, "C": 0, "D": 3, "E": 16, "F": 18, "G": 31, "H": 30}, "predicted_other_confidence_distribution_pct": {"A": 0.0, "B": 0.0, "C": 0.0, "D": 3.061224489795918, "E": 16.3265306122449, "F": 18.367346938775512, "G": 31.63265306122449, "H": 30.612244897959183}}
